{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77bca863",
   "metadata": {},
   "source": [
    "# Demo for DAGify\n",
    "In this demo, plan is pre-infered by our trained plan model.\n",
    "We have sloved 4 example in our demo, the completed result can be seen in \"demo/demo.jsonl\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.api import *\n",
    "from util.prompt_template import *\n",
    "import json5\n",
    "import requests\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inital path\n",
    "filter_modal_name = \"mmqa_filter\"\n",
    "plan_path = \"demo/test.jsonl\"\n",
    "store_path = \"demo/demo.jsonl\"\n",
    "log_path = \"demo/log.txt\"\n",
    "plan_data = read_jsonl(plan_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280704b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre load embedding of multimodal info\n",
    "image_emb = load_json_from_parquet(\"dataset/embedding/mmqa_dev_imgs_embedding.parquet\")\n",
    "table_emb = load_json_from_parquet(\"dataset/embedding/mmqa_dev_tabs_embedding.parquet\")\n",
    "text_emb = load_json_from_parquet(\"dataset/embedding/mmqa_dev_texts_embedding.parquet\")\n",
    "\n",
    "# data preprcess\n",
    "info_dict = dict()\n",
    "image_info = read_jsonl(\"dataset/data/mmqa/MMQA_images.jsonl\")\n",
    "for i in image_info:\n",
    "    info_dict[i[\"id\"]] = i\n",
    "text_info = read_jsonl(\"dataset/data/mmqa/MMQA_tables_md_cleaned.jsonl\")\n",
    "for i in text_info:\n",
    "    info_dict[i[\"id\"]] = i\n",
    "table_info = read_jsonl(\"dataset/data/mmqa/MMQA_texts.jsonl\")\n",
    "for i in table_info:\n",
    "    info_dict[i[\"id\"]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding related func\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0\n",
    "    cosine_sim = dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "    return cosine_sim\n",
    "\n",
    "def cal_query_docs_similarity(query: str, docs: list, topK: int) -> list[dict]:\n",
    "    url = \"\"  # Replace with your actual embedding service URL, use embedding_server.py\n",
    "    data = {\"texts\": [query]}\n",
    "    response = requests.post(url, json=data)\n",
    "    query_emb = response.json()[\"embeddings\"][0]\n",
    "\n",
    "    res = []\n",
    "    for doc in docs:\n",
    "        for dictory in [image_emb, table_emb, text_emb]:\n",
    "            if doc in dictory:\n",
    "                doc_emb = dictory[doc]\n",
    "                similarity = cosine_similarity(query_emb, doc_emb)\n",
    "                res.append({\"id\": doc, \"similarity\": similarity})\n",
    "    sorted_res = sorted(res, key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    return sorted_res[:topK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18a247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recovery related func\n",
    "def llm_rewrite_query(query: str, chat_model: str, client, history_dict: dict) -> str:\n",
    "    for key, value in history_dict.items():\n",
    "        if key in query:\n",
    "            query = query.replace(key, value)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": rewrite_query_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Original sub-query: {query}\",\n",
    "        },\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        temperature=0,\n",
    "        messages=messages,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def llm_direct_answer(query: str, chat_model: str, client, history_dict: dict) -> str:\n",
    "    for key, value in history_dict.items():\n",
    "        if key in query:\n",
    "            query = query.replace(key, value)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": direct_answer_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Question: {query}\",\n",
    "        },\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        temperature=0,\n",
    "        messages=messages,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb55b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter related func\n",
    "def get_img_filter_mesages(\n",
    "    question: str,\n",
    "    img_title: str,\n",
    "    image_name: str,\n",
    ") -> list:\n",
    "    img_dir = \"\"  # Replace with your actual image directory\n",
    "    image_type, b64_img = get_base64_img(image_name=image_name, img_dir=img_dir)\n",
    "    system_inputs = []\n",
    "    system_inputs.append({\"type\": \"text\", \"text\": filter_instruction})\n",
    "    user_inputs = []\n",
    "    user_inputs.append(\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"The title of the candidate image is {img_title}. The content of the candidate image is \",\n",
    "        }\n",
    "    )\n",
    "    user_inputs.append(\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/{image_type};base64,{b64_img}\"},\n",
    "        }\n",
    "    )\n",
    "    user_inputs.append({\"type\": \"text\", \"text\": f\"**Question:**{question}\"})\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_inputs,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_inputs,\n",
    "        },\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def docs_filter(question: str, docs: list, filter_model: str, filter_client) -> list:\n",
    "    filter_res = []\n",
    "    for doc in docs:\n",
    "        id = doc[\"id\"]\n",
    "        item = info_dict[id]\n",
    "        title = item[\"title\"]\n",
    "        if \"path\" in item:\n",
    "            path = item[\"path\"].replace(item[\"path\"].split(\".\")[1], \"png\")\n",
    "            messages = get_img_filter_mesages(question, title, path)\n",
    "        elif \"table\" in item:\n",
    "            table = item[\"table\"]\n",
    "            table_name = item[\"table_name\"]\n",
    "            table_input_template = \"**Title:**{title}\\n**Table Name:**{table_name}\\n**Table:**{table}\\n**Question:**{question}\"\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": filter_instruction,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": table_input_template.format(\n",
    "                        question=question,\n",
    "                        title=title,\n",
    "                        table_name=table_name,\n",
    "                        table=table,\n",
    "                    ),\n",
    "                },\n",
    "            ]\n",
    "        else:\n",
    "            text = item[\"text\"]\n",
    "            text_input_template = \"**Text Title:**{title}\\n**Text content:**{text}\\n**Question:**{question}\"\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": filter_instruction,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text_input_template.format(\n",
    "                        question=question, title=title, text=text\n",
    "                    ),\n",
    "                },\n",
    "            ]\n",
    "        completion = filter_client.chat.completions.create(\n",
    "            model=filter_model, messages=messages, temperature=0.1, top_p=0.001\n",
    "        )\n",
    "        output = completion.choices[0].message.content\n",
    "\n",
    "        output = json5.loads(output)\n",
    "        output[\"doc_id\"] = id\n",
    "        output[\"title\"] = title\n",
    "        filter_res.append(output)\n",
    "    return sorted(filter_res, key=lambda x: x[\"score\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817d4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute node func\n",
    "def execute_node(\n",
    "    name: str,\n",
    "    query: str,\n",
    "    action: str,\n",
    "    history_dict: dict,\n",
    "    text_filtered_ids: list,\n",
    "    tabs_filtered_ids: list,\n",
    "    imgs_filtered_ids: list,\n",
    "    filter_client,\n",
    "    llm_chat_client,\n",
    "    chat_model,\n",
    "    topK=5,\n",
    ") -> tuple:\n",
    "    for key, value in history_dict.items():\n",
    "        if key in query:\n",
    "            query = query.replace(key, value)\n",
    "    if action == \"text_retrieval\":\n",
    "        corpus = text_filtered_ids + tabs_filtered_ids\n",
    "    elif action == \"image_retrieval\":\n",
    "        corpus = imgs_filtered_ids\n",
    "    elif action == \"no_retrieval\":\n",
    "        corpus = []\n",
    "    else:\n",
    "        corpus = text_filtered_ids + tabs_filtered_ids + imgs_filtered_ids\n",
    "\n",
    "    docs = cal_query_docs_similarity(query, corpus, topK)\n",
    "\n",
    "    filter_res = docs_filter(\n",
    "        question=query,\n",
    "        docs=docs,\n",
    "        filter_model=filter_modal_name,\n",
    "        filter_client=filter_client,\n",
    "    )\n",
    "    filter_infos = []\n",
    "    for m in filter_res:\n",
    "        if m[\"score\"] > 0:\n",
    "            filter_infos.append(\n",
    "                f'**Titile**{m[\"title\"]}\\n**Key_info**{m[\"key_information\"]}'\n",
    "            )\n",
    "\n",
    "    # 将过滤后的信息和query包装发给llm获取结果，然后返回\n",
    "    completion = llm_chat_client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": execute_node_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'**question:**{query}**information:**{\" ||| \".join(filter_infos)}**answer**',\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content, filter_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:07<00:23,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \u001b[92m\"qid\"\u001b[0m: \u001b[0m\u001b[0m\"8238d72cff251700417aad30776b9dd6\",\n",
      "    \u001b[92m\"question\"\u001b[0m: \u001b[0m\u001b[0m\"What role did George Hilton play in \\\"The Atlantis Interceptors\\\"?\",\n",
      "    \u001b[92m\"ground_truth\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        \"Professor Peter Saunders\"\n",
      "    ],\n",
      "    \u001b[92m\"supporting_context\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        {\n",
      "            \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"43973134a8d5872cf47226bf5e650d31\",\n",
      "            \u001b[92m\"doc_part\"\u001b[0m: \u001b[0m\u001b[0m\"table\"\n",
      "        }\n",
      "    ],\n",
      "    \u001b[92m\"plan_log\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        {\n",
      "            \u001b[92m\"name\"\u001b[0m: \u001b[0m\u001b[0m\"Q1\",\n",
      "            \u001b[92m\"query\"\u001b[0m: \u001b[0m\u001b[0m\"What role did George Hilton play in \\\"The Atlantis Interceptors\\\"?\",\n",
      "            \u001b[92m\"action\"\u001b[0m: \u001b[0m\u001b[0m\"text_retrieval\",\n",
      "            \u001b[92m\"dependencies\"\u001b[0m: \u001b[0m\u001b[0m[],\n",
      "            \u001b[92m\"answer\"\u001b[0m: \u001b[0m\u001b[0m\"Professor Peter Saunders\",\n",
      "            \u001b[92m\"filter_res\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m5,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"| Actor | Role |\\n| George Hilton | Professor Peter Saunders |\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"43973134a8d5872cf47226bf5e650d31\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"The Atlantis Interceptors\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m2,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"George Hilton starred in 'The Atlantis Interceptors'.\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"921550d7e5d978c2392ecda28841b9d7\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"The Atlantis Interceptors\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"4aa30a8a0c5796576fd3a562a35e4921\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"The Atlantis Conspiracy\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"e3477a4791c53a843dea40e2d366c60d\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"The Atlantis Interceptors\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"0dec4cc3e3850299af76b2db943fa466\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Atlantis (TV programme)\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:41<00:46, 23.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \u001b[92m\"qid\"\u001b[0m: \u001b[0m\u001b[0m\"106ad70b10566792afb55afa2d5394dd\",\n",
      "    \u001b[92m\"question\"\u001b[0m: \u001b[0m\u001b[0m\"Which Irandhir Santos film was more recent, Elite Squad: The Enemy Within or A Febre do Rato?\",\n",
      "    \u001b[92m\"ground_truth\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        \"A Febre do Rato\"\n",
      "    ],\n",
      "    \u001b[92m\"supporting_context\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        {\n",
      "            \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"a3d423285d409df1281a7696055381fb\",\n",
      "            \u001b[92m\"doc_part\"\u001b[0m: \u001b[0m\u001b[0m\"table\"\n",
      "        },\n",
      "        {\n",
      "            \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"a3d423285d409df1281a7696055381fb\",\n",
      "            \u001b[92m\"doc_part\"\u001b[0m: \u001b[0m\u001b[0m\"table\"\n",
      "        }\n",
      "    ],\n",
      "    \u001b[92m\"plan_log\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        {\n",
      "            \u001b[92m\"name\"\u001b[0m: \u001b[0m\u001b[0m\"Q1\",\n",
      "            \u001b[92m\"query\"\u001b[0m: \u001b[0m\u001b[0m\"What is the release year of 'Elite Squad: The Enemy Within'?\",\n",
      "            \u001b[92m\"action\"\u001b[0m: \u001b[0m\u001b[0m\"text_retrieval\",\n",
      "            \u001b[92m\"dependencies\"\u001b[0m: \u001b[0m\u001b[0m[],\n",
      "            \u001b[92m\"answer\"\u001b[0m: \u001b[0m\u001b[0m\"2010\",\n",
      "            \u001b[92m\"filter_res\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m5,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"The film was released in Brazil on October 8, 2010.\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"449df6017283959f7c6625d1464c97b0\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Elite Squad: The Enemy Within\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"04b2fc92f5673907bf8befe01260c18b\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"The Squad (2015 film)\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"29c6553af45e6f1d1fd7c03ea7a2ed35\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Behind Enemy Lines: Colombia\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"23bad9279655a79c708b730fbc9ca15a\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Arsenal (2017 film)\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"f4b41f66bf13af106a32b268170b1f0b\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Polis Evo 2\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \u001b[92m\"name\"\u001b[0m: \u001b[0m\u001b[0m\"Q2\",\n",
      "            \u001b[92m\"query\"\u001b[0m: \u001b[0m\u001b[0m\"What is the release year of 'A Febre do Rato'?\",\n",
      "            \u001b[92m\"action\"\u001b[0m: \u001b[0m\u001b[0m\"text_retrieval\",\n",
      "            \u001b[92m\"dependencies\"\u001b[0m: \u001b[0m\u001b[0m[],\n",
      "            \u001b[92m\"answer\"\u001b[0m: \u001b[0m\u001b[0m\"2012\",\n",
      "            \u001b[92m\"filter_res\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m4,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"Febre do Rato is a 2012 Brazilian film.\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"d4df60e47e166da43ac6b7edf6c0bf4c\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Febre do Rato\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"ac539aaf03dbe751b7cc6d26eea666ab\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Tatuagem (film)\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"fb54be6d1859aaa21606aea25cf1cede\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"I Travel Because I Have to, I Come Back Because I Love You\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"2a730222abe7eea2e835a58106583546\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Aquarius (film)\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"f2e0b72246f9256602e84c8c0061f43e\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Absence (film)\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \u001b[92m\"name\"\u001b[0m: \u001b[0m\u001b[0m\"Q3\",\n",
      "            \u001b[92m\"query\"\u001b[0m: \u001b[0m\u001b[0m\"Which film is more recent: 'Elite Squad: The Enemy Within' (Q1) or 'A Febre do Rato' (Q2)?\",\n",
      "            \u001b[92m\"action\"\u001b[0m: \u001b[0m\u001b[0m\"no_retrieval\",\n",
      "            \u001b[92m\"dependencies\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "                \"Q1\",\n",
      "                \"Q2\"\n",
      "            ],\n",
      "            \u001b[92m\"answer\"\u001b[0m: \u001b[0m\u001b[0m\"'A Febre do Rato' (2012)\",\n",
      "            \u001b[92m\"filter_res\"\u001b[0m: \u001b[0m\u001b[0m[]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:55<00:18, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \u001b[92m\"qid\"\u001b[0m: \u001b[0m\u001b[0m\"08f92dc7e86cdae17365b2c16f90b839\",\n",
      "    \u001b[92m\"question\"\u001b[0m: \u001b[0m\u001b[0m\"What object is in front of Felicia Day's face?\",\n",
      "    \u001b[92m\"ground_truth\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        \"microphone\"\n",
      "    ],\n",
      "    \u001b[92m\"supporting_context\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        {\n",
      "            \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"d179a14875639d9cfb680f784223b271\",\n",
      "            \u001b[92m\"doc_part\"\u001b[0m: \u001b[0m\u001b[0m\"image\"\n",
      "        }\n",
      "    ],\n",
      "    \u001b[92m\"plan_log\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        {\n",
      "            \u001b[92m\"name\"\u001b[0m: \u001b[0m\u001b[0m\"Q1\",\n",
      "            \u001b[92m\"query\"\u001b[0m: \u001b[0m\u001b[0m\"What object is in front of Felicia Day's face?\",\n",
      "            \u001b[92m\"action\"\u001b[0m: \u001b[0m\u001b[0m\"image_retrieval\",\n",
      "            \u001b[92m\"dependencies\"\u001b[0m: \u001b[0m\u001b[0m[],\n",
      "            \u001b[92m\"answer\"\u001b[0m: \u001b[0m\u001b[0m\"A microphone\",\n",
      "            \u001b[92m\"filter_res\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m5,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"Title: Felicia Day Interview; Description: A microphone is positioned in front of Felicia Day's face.\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"d179a14875639d9cfb680f784223b271\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Felicia Day\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"0a09689860fb4a2ad69f55b611bfe20b\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Natasha Leggero\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"971b2305045ca074690333bcf928d841\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Rachel Dratch\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"f368e6090905b0d3a0ccb6bb89906180\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Mamrie Hart\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"51f3871beb6dccc09a271a7789af0d31\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Kathy Griffin\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:12<00:00, 18.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \u001b[92m\"qid\"\u001b[0m: \u001b[0m\u001b[0m\"d9603aa82acbcbe8657cee167fef0c07\",\n",
      "    \u001b[92m\"question\"\u001b[0m: \u001b[0m\u001b[0m\"What dub language was used by Gwen Tennyson in Animated series of Parignya Pandya Shah?\",\n",
      "    \u001b[92m\"ground_truth\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        \"Hindi\"\n",
      "    ],\n",
      "    \u001b[92m\"supporting_context\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        {\n",
      "            \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"c69dc5d997f470f873bffeb748eeaace\",\n",
      "            \u001b[92m\"doc_part\"\u001b[0m: \u001b[0m\u001b[0m\"table\"\n",
      "        }\n",
      "    ],\n",
      "    \u001b[92m\"plan_log\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "        {\n",
      "            \u001b[92m\"name\"\u001b[0m: \u001b[0m\u001b[0m\"Q1\",\n",
      "            \u001b[92m\"query\"\u001b[0m: \u001b[0m\u001b[0m\"What dub language was used by Gwen Tennyson in Animated series of Parignya Pandya Shah?\",\n",
      "            \u001b[92m\"action\"\u001b[0m: \u001b[0m\u001b[0m\"text_retrieval\",\n",
      "            \u001b[92m\"dependencies\"\u001b[0m: \u001b[0m\u001b[0m[],\n",
      "            \u001b[92m\"answer\"\u001b[0m: \u001b[0m\u001b[0m\"Hindi\",\n",
      "            \u001b[92m\"filter_res\"\u001b[0m: \u001b[0m\u001b[0m[\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m5,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"| Program title | Original voice | Character | Dub Language | Original Language | Number of Episodes | Original airdate | Dubbed airdate | Notes |\\n| Ben 10 | Meagan Smith | Gwen Tennyson | Hindi | English | 52 | 12/27/2005- 4/15/2008 |  |  |\\n| Ben 10: Alien Force | Ashley Johnson | Gwen Tennyson | Hindi | English | 46 | 4/18/2008– 4/26/2010 |  |  |\\n| Ben 10: Ultimate Alien | Ashley Johnson | Gwen Tennyson | Hindi | English | 52 | 4/23/2010– 4/31/2011 |  |  |\\n| Ben 10: Omniverse | Ashley Johnson | Gwen Tennyson | Hindi | English | 80 | 8/1/2012-11/14/2014 | 11/26/2012-Early 2015 |  |\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"c69dc5d997f470f873bffeb748eeaace\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Parignya Pandya Shah\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"684b233d4923eecd95fef270dc82e9c2\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Bepanah Pyaar\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"7e3abdc85d07b49a98ef332e39686080\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Shaktimaan: The Animated Series\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"611841a71c5e2fd7cd8696e3b0216ab3\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Make Way for Noddy\"\n",
      "                },\n",
      "                {\n",
      "                    \u001b[92m\"score\"\u001b[0m: \u001b[0m\u001b[0m0,\n",
      "                    \u001b[92m\"key_information\"\u001b[0m: \u001b[0m\u001b[0m\"\",\n",
      "                    \u001b[92m\"doc_id\"\u001b[0m: \u001b[0m\u001b[0m\"e40de1bb7f3d24662ecb59062704b688\",\n",
      "                    \u001b[92m\"title\"\u001b[0m: \u001b[0m\u001b[0m\"Wendy Hoopes\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "dataset_path = \"dataset/data/mmqa/MMQA_dev.jsonl\"  # Replace with your actual dataset path\n",
    "\n",
    "dataset = read_jsonl(dataset_path)\n",
    "query_dict = dict()\n",
    "for item in dataset:\n",
    "    query_dict[item[\"question\"]] = item\n",
    "\n",
    "\n",
    "res = []\n",
    "\n",
    "# Replace with your api keys, URLs and model names\n",
    "llm_chat_api_key = \"\"\n",
    "llm_chat_base_url = \"\"\n",
    "llm_chat_chat_model = \"gpt-4o-2024-11-20\"\n",
    "\n",
    "filter_api_key = \"\"\n",
    "filter_base_url = \"\"\n",
    "\n",
    "\n",
    "f, processed = get_output_file(store_path, force=False)\n",
    "filter_client = openai.Client(api_key=filter_api_key, base_url=filter_base_url)\n",
    "llm_chat_client = openai.Client(api_key=llm_chat_api_key, base_url=llm_chat_base_url)\n",
    "\n",
    "\n",
    "log = \"\"\n",
    "for plan in tqdm(plan_data):\n",
    "    try:\n",
    "        question = (\n",
    "            plan[\"prompt\"]\n",
    "            .split(\"user\\n\")[1]\n",
    "            .replace(\"<|im_end|>\\n<|im_start|>assistant\\n\", \"\")\n",
    "        )\n",
    "        plan_str = plan[\"predict\"]\n",
    "        query_item = query_dict[question]\n",
    "        qid = query_item[\"qid\"]\n",
    "        if qid in processed:\n",
    "            continue\n",
    "        plan = json5.loads(plan_str)\n",
    "        history_dict = dict()\n",
    "        plan_log = []\n",
    "        for node in plan:\n",
    "            node_res, filter_res = execute_node(\n",
    "                node[\"name\"],\n",
    "                node[\"query\"],\n",
    "                node[\"action\"],\n",
    "                history_dict=history_dict,\n",
    "                text_filtered_ids=query_item[\"metadata\"][\"text_doc_ids\"],\n",
    "                tabs_filtered_ids=[query_item[\"metadata\"][\"table_id\"]],\n",
    "                imgs_filtered_ids=query_item[\"metadata\"][\"image_doc_ids\"],\n",
    "                filter_client=filter_client,\n",
    "                llm_chat_client=llm_chat_client,\n",
    "                chat_model=llm_chat_chat_model,\n",
    "            )\n",
    "\n",
    "            if \"I don't know\" in node_res:\n",
    "                node_res, filter_res = execute_node(\n",
    "                    node[\"name\"],\n",
    "                    node[\"query\"],\n",
    "                    \"general_retrieval\",\n",
    "                    history_dict=history_dict,\n",
    "                    text_filtered_ids=query_item[\"metadata\"][\"text_doc_ids\"],\n",
    "                    tabs_filtered_ids=[query_item[\"metadata\"][\"table_id\"]],\n",
    "                    imgs_filtered_ids=query_item[\"metadata\"][\"image_doc_ids\"],\n",
    "                    filter_client=filter_client,\n",
    "                    llm_chat_client=llm_chat_client,\n",
    "                    chat_model=llm_chat_chat_model,\n",
    "                )\n",
    "\n",
    "            if \"I don't know\" in node_res:\n",
    "                modified_query = llm_rewrite_query(\n",
    "                    node[\"query\"], llm_chat_chat_model, llm_chat_client, history_dict\n",
    "                )\n",
    "                node_res, filter_res = execute_node(\n",
    "                    node[\"name\"],\n",
    "                    modified_query,\n",
    "                    \"general_retrieval\",\n",
    "                    history_dict=history_dict,\n",
    "                    text_filtered_ids=query_item[\"metadata\"][\"text_doc_ids\"],\n",
    "                    tabs_filtered_ids=[query_item[\"metadata\"][\"table_id\"]],\n",
    "                    imgs_filtered_ids=query_item[\"metadata\"][\"image_doc_ids\"],\n",
    "                    filter_client=filter_client,\n",
    "                    llm_chat_client=llm_chat_client,\n",
    "                    chat_model=llm_chat_chat_model,\n",
    "                )\n",
    "\n",
    "            if \"I don't know\" in node_res:\n",
    "                node_res = llm_direct_answer(\n",
    "                    node[\"query\"], llm_chat_chat_model, llm_chat_client, history_dict\n",
    "                )\n",
    "                filter_res = \"llm answer\"\n",
    "\n",
    "            if \"I don't know\" in node_res:\n",
    "                node_res = \"\"\n",
    "                filter_res = \"node skipped\"\n",
    "\n",
    "            node[\"answer\"] = node_res\n",
    "            node[\"filter_res\"] = filter_res\n",
    "            plan_log.append(node)\n",
    "            history_dict[node[\"name\"]] = node_res\n",
    "\n",
    "        ans = {\n",
    "            \"qid\": qid,\n",
    "            \"question\": query_item[\"question\"],\n",
    "            \"ground_truth\": [a[\"answer\"] for a in query_item[\"answers\"]],\n",
    "            \"supporting_context\": query_item[\"supporting_context\"],\n",
    "            \"plan_log\": plan_log,\n",
    "        }\n",
    "        pretty_print_json(ans)\n",
    "        f.write(json.dumps(ans) + \"\\n\")\n",
    "        f.flush()\n",
    "    except Exception as e:\n",
    "        log += f\"{qid}:{e}\\n\\n\"\n",
    "        print(f\"{qid}:{e}\")\n",
    "        continue\n",
    "f.close()\n",
    "with open(log_path, \"w\") as f:\n",
    "    f.write(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24164a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zch_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
